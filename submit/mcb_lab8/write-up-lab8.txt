##########################################################################################
#LAB 8 write-up
#NAME: Hanshu Ding, Ling Tu
#LANGUAGE: mcb
##########################################################################################

######################################################
1. A description of how the phenomenon you picked to work on is expressed in your language, including IGT.
	#phenomenon: Wh-questions
	#description:
	WH-question in Matsigenka is similar to the interrogation patterns in English. The interrogation pronoun is put in the sentence initial position. The common interrogate gloss is presented below.
		     interrogative          gloss
			tata                `what'
			tyani        `who'/'which one (anim)'
			tyati        `which one (inanimate)'
			tya(ra)             `where', `how'
  While the subject or the object is the questioning target, we omit the subject/object marker to give a hint about it.
  ---answering some concerns Emily has on canvas: The overt subject and object NPs can co-occur with both the subj/obj marker. As for the wh-questions, I believe that only target questioning NP will be omitted. ---
When a peripheral argument (neither object nor subject) is being interrogated, neither subject marker nor object marker would be omitted. 
   Also, the word ‘why’ in Matsigenka cannot be presented as a single word, but a word ‘where/how’ plus a light verb ‘happen’. The light verb 'happen' here can be inflected with realis and subject markers. The implementation for word 'why' is out of the range we would like to touch for now, we are mainly focusing on implementing the word 'what' and 'who'. 
 (The word 'tyani and 'tyati' is represent as an independent word in Nanti resources, however in our corpus these words are seperated as 'tya-ni' and 'tya-ti', where the GLOSS are 'how.EMBED-ANIM'. To make it easier to deal with, we set our lexicon for 'who' as 'tya-ni'.) 

	#some IGT:
		tya-ni ne-ak-i=ri
		who.INTERR-AINM see-PERF-realis=3mO
		Who saw him?

		tya-ni i=ne-ak-i
		who.INTERR-ANIM 3mS=see-PERF-realis
		Whom did he see?

		tata i-og-ak-a
		what.INTERR 3mS-eat-PERF-realis.refl
		What did he eat?

###################################################################
2. A description of your implementation of this phenomenon:


Choices file:
We went back to the grammar matrix:
 -add a wh-question noun class, which includes two nouns: 
	1. tata -- '_thing_n_rel'
	2. tya-ni -- '_person_rel'
 -add aa adverb:
	tya=ra - 'why'

Based on the grammar we generated from the matrix, which the wh-qestions is implemented:

Tdl cleanup:
- Force wh-pronoun-noun-lex to require [CASE nlc] (non-locative) inputs instead (so that it doesn't accept PPs as inputs) 
	mcb.tdl: ---------------
		wh-pronoun-noun-lex := ... &
		  [ SYNSEM [ LOCAL [ CAT [ HEAD noun & [ CASE nlc ], ... ] ] ] ].
- Replace verb_trans_compclause-verb-lex with two rules, one for propositions and one for questions, and recategorize compclause verbs to be either prop or ques
	mcb.tdl: ---------------
		verb_trans_compclause-prop-verb-lex := clausal-nom-verb-lex & clausal-second-arg-trans-lex-item &
		  [ SYNSEM [ LOCAL.CAT.VAL.COMPS < [ LOCAL [ CAT [ HEAD verb &
		                                                        [ FORM subordinate ],
		                                                   WH.BOOL - ],
		                                             CONT.HOOK.INDEX.SF prop ] ] >,
		             NON-LOCAL.QUE.LIST < > ] ].
		verb_trans_compclause-ques-verb-lex := clausal-nom-verb-lex & clausal-second-arg-trans-lex-item &
		  [ SYNSEM [ LOCAL.CAT.VAL.COMPS < [ LOCAL [ CAT [ HEAD verb &
		                                                        [ FORM subordinate ] ],
		                                             CONT.HOOK.INDEX.SF ques ] ] >,
		             NON-LOCAL.QUE.LIST < > ] ].
	lexicon.tdl: ---------------
		ne_2 := verb_trans_compclause-prop-verb-lex &
		  [ STEM < "ne" >,
		    SYNSEM.LKEYS.KEYREL.PRED "_think_v_rel" ].
		sure := verb_trans_compclause-prop-verb-lex &
		  [ STEM < "sure" >,
		    SYNSEM.LKEYS.KEYREL.PRED "_remember-or-think_v_rel" ].
		ogo := verb_trans_compclause-prop-verb-lex &
		  [ STEM < "ogo" >,
		    SYNSEM.LKEYS.KEYREL.PRED "_know_v_rel" ].
		kogako := verb_trans_compclause-ques-verb-lex &
		  [ STEM < "kogako" >,
		    SYNSEM.LKEYS.KEYREL.PRED "_ask_v_rel" ].

#IGT:
	tya-ni mag-i ?
	who.INTERR-ANIM sleep-realis ?
	Who sleeps ?

	tata i-ogia-i osheto ?
	what.INTERR 3mS-chase-realis dogs ?
	What do the dogs chase ?

	tya-ni kogako-ak-i tata i-ogia-i osheto ?
	who.INTERR-ANIM ask-PERF-realis what.EMBED 3mS-chase-realis dogs ?
	Who asked what the dogs chase ?


#########################################################
3. A description of any clean up work you did to get generation down to a reasonable number of outputs, including:


MMT before/after eng2mcb:
	(** marks reduced ambiguity
	 -- marks newly working parses)

	** 1) 24 results -> 4 results
	-- 2) not parsing -> 8 results
	   3) not parsing -> not parsing
	** 4) 240 results -> 40 results
	   5) not parsing -> not parsing
	   5) not parsing -> not parsing
	   6) not parsing -> not parsing
	   7) not parsing -> not parsing
	-- 8) not parsing -> 160 results
	-- 9) not parsing -> 64 results
	   10) not parsing -> not parsing
	-- 11) not parsing -> 8 results
	   12) not parsing -> not parsing
	   13) not parsing -> not parsing
	   14) not parsing -> not parsing
	** 15) 24 results -> 4 results
	   16) not parsing -> not parsing
	** 17) 216 results -> 4 results
	   18) not parsing -> not parsing
	-- 19) not parsing -> 8 results
	   20) not parsing -> not parsing
	   21) not parsing -> not parsing
	   22) not parsing -> not parsing
	   23) not parsing -> not parsing
	   24) not parsing -> not parsing
	   25) not parsing -> not parsing
	   26) not parsing -> not parsing

Reduced the following ambiguity sources for sentences described in the grammar below, as well as a few other cleanup changes:
- Sentence word order
- Spurious adding of locative suffix "-ku"
- Gender underspecification of nouns

-------------------------------------
Lexical cleanup (reducing verb choice ambiguity, unifying MRS relations, adding missing words):
- Comment out second meaning of verb "og" ("eat") and dump all additional meanings of "og" into the commented out lexical entry for now
	og_1 := verb_trans-verb-lex &
	  [ STEM < "og" >,
	    SYNSEM.LKEYS.KEYREL.PRED "_eat_v_rel" ].
	; og_2 := verb_trans-verb-lex &
	;   [ STEM < "og" >,
	;     SYNSEM.LKEYS.KEYREL.PRED "_do.until-or-put_v_rel" ].
- Cleaned up lexical entry for "ne", which can mean "see" in the perceptual sense or "see/think" in the cognitive sense for mmt purpose
	ne_2 := verb_trans_compclause-prop-verb-lex &
	  [ STEM < "ne" >,
	    SYNSEM.LKEYS.KEYREL.PRED "_think_v_rel" ].
- Changed "ogio" predication "_follow_v_rel" to "_chase_v_rel" for mmt purpose
- Added lexical entry for "ask", which was not in our corpus but was in Matsigenka texts. Made it a compclause for now to get it to parse, not sure if this is right or not:
	kogako := verb_trans_compclause-verb-lex &
	  [ STEM < "kogako" >,
	    SYNSEM.LKEYS.KEYREL.PRED "_ask_v_rel" ].
- Changed lexical entry for "*pito" to "*pito-tsi" to simplify the "alienable" noun situation for now (and comment out the -tsi suffix lexical rule in our mmt grammar)
	*pito-tsi := noun_vessel-noun-lex &
  		[ STEM < "*pito-tsi" >,
- Specify gender for animal-noun-lex to remove ambiguity in animal subject MMT output.
	animals-noun-lex := noun-lex & noun-pc-alien-poss-rule-dtr & noun-pc-poss-rule-dtr &
	  [ SYNSEM.LOCAL.CONT.HOOK.INDEX.PNG [ PER 3rd,
	                                       GEND m ] ].

-----------------------------------
Word order cleanup (removing parse and generator ambiguity for word order):
- Remove comp-head, subj-head, comp-head-2
	rules.tdl: ---------------
		; comp-head := comp-head-phrase.
		; subj-head := subj-head-phrase.
		; comp-head-2 := comp-head-phrase-2.
- Force all SUBJ-fulfilling rules to fire before COMPS-fulfilling rules (so that VSO is enabled but VOS is disallowed) by having all COMPS related rules require [ SUBJ < > ].
	+ Replace basic-head-opt-subj-phrase (head daughter of optional subj phrase has COMPS requirement already fulfilled) with basic-head-opt-comp-phrase (head daughter of optional comp phrase has SUBJ requirement already fulfilled)
	+ Add requirement to head-comp-phrase for head daughter SUBJ to be empty.
	+ Remove requirement to extracted-subj-phrase for head daughter COMPS to be empty and add requirement to extracted-comp-phrase for head daughter SUBJ to be empty to allow embedded question phrases like "who asked what the dogs chase" to also parse correctly.

	mcb.tdl: ---------------
		; basic-head-opt-subj-phrase :+ [ HEAD-DTR.SYNSEM.LOCAL.CAT.VAL.COMPS < > ].
		basic-head-opt-comp-phrase :+ [ HEAD-DTR.SYNSEM.LOCAL.CAT.VAL.SUBJ < > ].
		head-comp-phrase := basic-head-1st-comp-phrase & head-initial-head-nexus &
		  [ HEAD-DTR.SYNSEM.LOCAL.CAT [ HEAD.INIT +,
		                                VAL.SUBJ < >].	
		extracted-comp-phrase := basic-extracted-comp-phrase &
		  [ HEAD-DTR.SYNSEM.LOCAL.CAT.VAL.SUBJ < > ].
		;  [ HEAD-DTR.SYNSEM.LOCAL.CAT.VAL.SUBJ cons ].
		extracted-subj-phrase := basic-extracted-subj-phrase &
		  [ SYNSEM.LOCAL.CAT.HEAD verb ].
		;  [ HEAD-DTR.SYNSEM.LOCAL.CAT.VAL.COMPS < >,
		;    SYNSEM.LOCAL.CAT.HEAD verb ].

------------------------------------
Noun pc cleanup (removing parse and generator ambiguity for noun-pc combinatorial possibilities):
- Noun pcs weren't consistently firing, so we reorganized them to fire in the correct order by hooking up the correct dtr inheritance (thereby also addressing Emily's comment last week: "But the affixes attach one at a time, so your morphology has to be set up so that the prefixes attach after the suffixes (and some prefix PC takes a suffix PC as its daughter) or vice versa. If they both attach to the root, you never get both in the same word.")
	[ no tdl attached because we touched most noun-pc classes, but basically we reorganized the dtr supertypes ]

------------------------------------
Coordination cleanup (removing parse ambiguity for NP coordination, improving accuracy of behavior for S coordination):
- Remove np6 coordination rules for asyndetic coordination on NPs
	rules.tdl: ---------------
		; np6-top-coord := np6-top-coord-rule.
		; np6-bottom-coord := np6-bottom-coord-rule.
	mcb.tdl: ---------------
		; 	np6-top-coord-rule := basic-np-top-coord-rule & apoly-top-coord-rule &
		; 	  [ SYNSEM.LOCAL.COORD-STRAT "6" ].
		; 	np6-bottom-coord-rule := unary-bottom-coord-rule & np-bottom-coord-phrase &
		; 	  [ SYNSEM.LOCAL [ COORD-STRAT "6",
		; 	                   COORD-REL.PRED "_and_coord_rel" ] ].
- Add S coordinating strategy for coordination with different SUBJ NPs. Previously, a sentence like "dogs chase cars and cats chase dogs" did not parse because the asyndetic VP coordination rule was looking for VPs as its daughters.
	(previously, this sentence parsed: <FIXTHIS>
		i-ogia-i *pito-tsi i-og-i matsontsori osheto
		dogs chase cars and eat cats
	 while this sentence did not:
	 	i-ogia-i osheto *pito-tsi , i-ogia-i matsontsori osheto
	 	dogs chase cars and cats chase dogs)

	mcb.tdl: ---------------
		;;; S Coordination Strategy 1
		s1-top-coord-rule := basic-s-top-coord-rule & apoly-top-coord-rule &
		  [ SYNSEM.LOCAL.COORD-STRAT "1" ].
		s1-bottom-coord-rule := unary-bottom-coord-rule & s-bottom-coord-phrase &
		  [ SYNSEM.LOCAL [ COORD-STRAT "1",
		                   COORD-REL.PRED "_and_coord_rel" ] ].
	rules.tdl: ---------------
		s1-top-coord := s1-top-coord-rule.
		s1-bottom-coord := s1-bottom-coord-rule.

--------------------------------------
Possessives cleanup (removing generator ambiguity of poss prefixes by constraining person/gender):
- Fix possessives to specify correct PER and GEND, which were previously underspecified, by making subclasses of noun-pc-poss-lex-rule.
	mcb.tdl: ---------------
		noun-pc-poss3m-lex-rule := noun-pc-poss-lex-rule &
		  [ C-CONT.RELS.LIST.FIRST.ARG0.PNG [ PER 3rd,
		                                      GEND m] ].
		noun-pc-poss3f-lex-rule := noun-pc-poss-lex-rule &
		  [ C-CONT.RELS.LIST.FIRST.ARG0.PNG [ PER 3rd,
		                                      GEND f] ].
		noun-pc-poss1-lex-rule := noun-pc-poss-lex-rule &
		  [ C-CONT.RELS.LIST.FIRST.ARG0.PNG [ PER 1st] ].
		noun-pc-poss2-lex-rule := noun-pc-poss-lex-rule &
		  [ C-CONT.RELS.LIST.FIRST.ARG0.PNG [ PER 2nd] ].
	irules.tdl: ---------------
		noun-pc-poss3m-prefix :=
		%prefix (* i-)
		noun-pc-poss3m-lex-rule.
		noun-pc-poss3f-prefix :=
		%prefix (* o-)
		noun-pc-poss3f-lex-rule.
		noun-pc-poss1-prefix :=
		%prefix (* no-)
		noun-pc-poss1-lex-rule.
		noun-pc-poss2-prefix :=
		%prefix (* pi-)
		noun-pc-poss2-lex-rule.

-------------------------------------
Nonlocative suffix cleanup (removing generator ambiguity on locative suffix attaching to all nouns):
- Constrain intranstive and transitive verb class to have [CASE nlc] (non-locative) subject and complement to reduce MMT ambiguity. The copula PP is type aux-lex and will not inherit this change, allowing it to still take the nlc PP.
	mcb.tdl: ---------------
		transitive-verb-lex-super := main-verb-lex & transitive-lex-item &
		  [ SYNSEM.LOCAL.CAT.VAL.COMPS < #comps >,
		    ARG-ST < [ LOCAL.CAT.HEAD noun &
		                              [ CASE nlc ] ],
		             #comps &
		             [ LOCAL.CAT cat-sat &
		                         [ VAL [ SPR < >,
		                                 COMPS < > ],
		                           HEAD noun &
		                                [ CASE nlc ] ] ] > ].
		intransitive-verb-lex := main-verb-lex & intransitive-lex-item &
		  [ SYNSEM.LOCAL.CAT.VAL.COMPS < >,
		    ARG-ST < [ LOCAL.CAT.HEAD noun &
		               [ CASE nlc ] ] >,
		    INFLECTED [ VERB-PC-REALISIRREALIS-SUFFIX-FLAG -,
		                VERB-PC-ASPECT-FLAG - ] ].


###############################################################
4: Description of the status of each MMT item.

MMT sentence semantics:
1) eng: Works (4 results)
   sje: (same)
2) eng: Works (8 results)
   sje: (same)
3) eng: Does not work, MRS is different ("pron_rel" is unknown because mcb does not use overt pronouns for "I chase you" so there is no relation for "I" and "you")
   sje: (same)
4) eng: Works (40 results)
   sje: Works (64 results)
5) Does not work, MCB not yet parsing due to negation not being implemented
6) eng: Does not work, MRS is different ("pron_rel" is unknown)
   sje: (same)
7) eng: Does not work, MRS is different ("pron_rel" is unknown)
   sje: Does not work, sje has this sentence SKIPPED
8) eng: Works (160 results)
   sje: Works (96 results)
   	*NOTE: A lot of ambiguity here is because our coordinating word "-ntiri" is inflected for the gender of the NP to its right, but we have not implemented gender agreement on this yet, so both coordinating words are generating, as well as both subject markers on the verb (since the coordinated NP has underspecified gender after coordination)
9) eng: Works (64 results)
   sje: (same)
    *NOTE: A lot of ambiguity here is because MCB verbs take an object marker if the object is definite but not if it is indefinite, and we haven't implemented anything to constrain the definite-ness of the nouns
10) eng: Does not work, unknown reason "transfer did 0 successful unifies and 0 failed ones"
   	sje: Works (96 results)
	 *SIDE NOTE: We checked the MRS and it seems correct, except that in MCB the sentence "cats chase dogs and sleep" would require anaphora resolution between the subject of chase and the subject of sleep, so "sleep" currently just has an unspecific 3rd-per masculine subject.
11) eng: Works (8 results), but the output generations are not correct
   	sje: (same)
   	 *NOTE: We believe that in MCB the polar questions require the topic NP in a post-verbal position and the other argument NP needs to be pre-verbal. For this sentence, our "correct" generation should be "matsontsori i-ogia-i=ri osheto ?" but our generations are variants on "ogia-i matsontsori osheto". The polar questions in Mcb are generally distinguished by intonation; we are not sure what in Eng/Sje would signal to the Mcb generator to treat the sentence as a polar question with this word order change.
12) Does not work, MCB not yet parsing due to non-copular APs not being implemented
13) eng: Does not work, MRS is different ("_in_p_rel" in Eng is "_loc_p_rel" in Mcb)
   	sje: Does not work, sje has this sentence SKIPPED
14) eng: Does not work, MRS is different ("_in_p_rel" in Eng is "_loc_p_rel" in Mcb)
   	sje: Does not work, sje has this sentence SKIPPED
15) eng: Works (4 results)
   	sje: Does not work, sje has this sentence SKIPPED
16) eng: Does not work, MRS is different ("_in_p_rel" in Eng is "_loc_p_rel" in Mcb)
   	sje: Does not work, sje has this sentence SKIPPED
17) eng: Works (4 results)
   	sje: Does not work, sje has this sentence SKIPPED
18) eng: Does not work, MCB not yet parsing (we are not really sure how to translate this sentence either) because we don't have non-pronomial possession implemented
	sje: (same)
19) eng: Works (8 results)
	sje: (same)
20) eng: Does not work, MRS is different ("_wh_q_rel" in Eng is "_which_q_rel" in Mcb, and it is also complaining about "_person_n_rel" but that looks the same in Mcb so we don't understand why that one is not mapping)
	sje: (same)
21) eng: Does not work, MRS is different ("_wh_q_rel" in Eng is "_which_q_rel" in Mcb, and it is also complaining about "_thing_n_rel" but that looks the same in Mcb so we don't understand why that one is not mapping)
	sje: (same)
22) eng: Does not work, MRS is different (same as #21, plus "pron_rel" is unknown)
	sje: (same)
23) eng: Does not work, MRS is different (same as combination of all of the issues in #20-22)
	sje: (same)
24) eng: Does not work, MRS is different (same as combination of all of the issues in #20-22)
	sje: (same)
25) eng: Does not work, MRS is different ("_because_subord_rel" needs to be implemented in Mcb - we should be able to do this next week, just didn't get to it when we did clausal modifiers)
	sje: Does not work, sje has this sentence SKIPPED
26) eng: Does not work, MRS is different ("_after_subord_rel" is not specified in Mcb - this is generally underspecified in Mcb as clausal combinations often leave temporal succession to be determined from context)
	sje: Does not work, sje has this sentence SKIPPED


##########################################################
5.A description of the performance of your final grammar for this week on the test suite and test corpus, as compared to your starting grammar.

	(1). How many items parsed?
	Corpus:
	- original:		39
	- new:			32
	Testsuite: 
	- original:		67
	- new:			58
	MMT:
	- original:		10
	- new:			19

	(2). What is the average number of parses per parsed item?
	Corpus:
	- original:		53.05
	- new:			67.72
	Testsuite: (well-formed sentences)
	- original:		4.32
	- new:			8.50
	MMT:
	- original:		3.30
	- new:			4.16

	(3). How many parses did the most ambiguous item receive?
	Corpus:
	- original:		752
	- new:			784
	Testsuite:
	- original:		40
	- new:			88
	MMT:
	- original:		10
	- new:			22

	This week, since we were focusing on the MMT in particular, we made a separate test suite for just MMT sentences and focused on performance of those (with two sentences skipped). We are including "Testsuite", which is mostly non-MMT sentences from previous labs, but we feel several of these sentences need to be rewritten to accomodate our new bias for VSO word order. Though many of our stats have gotten worse (overall corpus parsing, increased ambiguity), based purely on the metric of number of MMT sentences parsed, we have almost doubled our coverage.
	*NOTE: As per usual, since we have both a mcb_lab8_final and mcb_lab8_mmt, our tsdb testsuites can be found in mcb_lab8_final.

	(4). What new sources of ambiguity can you identify?
		- Much of our additional ambiguity comes from the addition of the WH-question framework. The infrastructure for these involves EX-COMP/EX-SUBJ/EX-ADJ unary branching rules that have added a lot of ambiguity to our parsing. So, after adding WH-questions our ambiguity actually exploded and a lot of work we did was cutting down ambiguity from there. Much of this ambiguity is expected, though, because of the argument dropping in Mcb can lead much NP resolution up to context.




------------------------------------------------
###Translations mapping/remapping###
	Existing relations:
	- sleep (mag) - GLOSS: sleep
	- eat (seka) - GLOSS: eat
	- hungry (taseg) - GLOSS: be.hungry
	Remapped relations:
	- cat -> jaguar (matsontsori) - GLOSS: jaguar -> _jaguar_n_rel
	- dog -> spider monkey (osheto) - GLOSS: spider.monkey	-> _dog_n_rel
	- car -> canoe (*pito) - GLOSS: canoe (always appears as canoe-ALIEN) -> _car_n_rel
	- park -> forest (inkenishi) - GLOSS: forest (always appears as forest=LOC) -> _park_n_rel
	- chase -> follow (ogia) - GLOSS: follow -> _chase_v_rel
	Adding to lexicon:
	- canoe (*pito) - This was in sentences 1350 and 1790, but not in our lexicon; 
	- to be hungry (taseg) - This was in our resource grammar "Matsigenka Texts Written By Matsigenka Authors" (2013, Pereira and Pereira)




